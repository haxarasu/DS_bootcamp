{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 02\n",
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the same dataframe as in the previous exercise.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>uid_user_15</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   numTrials  hour  uid_user_0  uid_user_1  uid_user_10  uid_user_11  \\\n",
       "0          1     5         0.0         0.0          0.0          0.0   \n",
       "1          2     5         0.0         0.0          0.0          0.0   \n",
       "2          3     5         0.0         0.0          0.0          0.0   \n",
       "3          4     5         0.0         0.0          0.0          0.0   \n",
       "4          5     5         0.0         0.0          0.0          0.0   \n",
       "\n",
       "   uid_user_12  uid_user_13  uid_user_14  uid_user_15  ...  labname_lab03  \\\n",
       "0          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "2          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "3          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "4          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "\n",
       "   labname_lab03s  labname_lab05s  labname_laba04  labname_laba04s  \\\n",
       "0             0.0             0.0             0.0              0.0   \n",
       "1             0.0             0.0             0.0              0.0   \n",
       "2             0.0             0.0             0.0              0.0   \n",
       "3             0.0             0.0             0.0              0.0   \n",
       "4             0.0             0.0             0.0              0.0   \n",
       "\n",
       "   labname_laba05  labname_laba06  labname_laba06s  labname_project1  \\\n",
       "0             0.0             0.0              0.0               1.0   \n",
       "1             0.0             0.0              0.0               1.0   \n",
       "2             0.0             0.0              0.0               1.0   \n",
       "3             0.0             0.0              0.0               1.0   \n",
       "4             0.0             0.0              0.0               1.0   \n",
       "\n",
       "   dayofweek  \n",
       "0          4  \n",
       "1          4  \n",
       "2          4  \n",
       "3          4  \n",
       "4          4  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../datasets/day-of-week-not-scaled.csv')\n",
    "df_scaled = pd.read_csv('../../datasets/dayofweek.csv')\n",
    "df['dayofweek'] = df_scaled['dayofweek']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('dayofweek', axis=1)\n",
    "y = df['dayofweek']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use the best parameters from the previous exercise and train the model of SVM.\n",
    "2. You need to calculate `accuracy`, `precision`, `recall`, `ROC AUC`.\n",
    "\n",
    " - `precision` and `recall` should be calculated for each class (use `average='weighted'`)\n",
    " - `ROC AUC` should be calculated for each class against any other class (all possible pairwise combinations) and then weighted average should be applied for the final metric\n",
    " - the code in the cell should display the result as below:\n",
    "\n",
    "```\n",
    "accuracy is 0.88757\n",
    "precision is 0.89267\n",
    "recall is 0.88757\n",
    "roc_auc is 0.97878\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.8875739644970414\n",
      "precision is 0.8926729169690374\n",
      "recall is 0.8875739644970414\n",
      "roc_auc is 0.9820332974866085\n"
     ]
    }
   ],
   "source": [
    "params = {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'}\n",
    "model = SVC(**params, probability=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "\n",
    "print(f'accuracy is {accuracy_score(y_test, y_pred)}')\n",
    "print(f'precision is {precision_score(y_test, y_pred, average='weighted')}')\n",
    "print(f'recall is {recall_score(y_test, y_pred, average='weighted')}')\n",
    "print(f'roc_auc is {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The same task for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.893491124260355\n",
      "precision is 0.8953094285678733\n",
      "recall is 0.893491124260355\n",
      "roc_auc is 0.9369245247365847\n"
     ]
    }
   ],
   "source": [
    "params = {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 23}\n",
    "model = DecisionTreeClassifier(**params, random_state=21)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "\n",
    "print(f'accuracy is {accuracy_score(y_test, y_pred)}')\n",
    "print(f'precision is {precision_score(y_test, y_pred, average='weighted')}')\n",
    "print(f'recall is {recall_score(y_test, y_pred, average='weighted')}')\n",
    "print(f'roc_auc is {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The same task for random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9289940828402367\n",
      "precision is 0.9300865038851309\n",
      "recall is 0.9289940828402367\n",
      "roc_auc is 0.9915076283905064\n"
     ]
    }
   ],
   "source": [
    "params = {'class_weight': None, 'criterion': 'gini', 'max_depth': 28, 'n_estimators': 50}\n",
    "model = RandomForestClassifier(**params, random_state=21)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "\n",
    "print(f'accuracy is {accuracy_score(y_test, y_pred)}')\n",
    "print(f'precision is {precision_score(y_test, y_pred, average='weighted')}')\n",
    "print(f'recall is {recall_score(y_test, y_pred, average='weighted')}')\n",
    "print(f'roc_auc is {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model.\n",
    "2. Analyze: for which `weekday` your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which `labname` and for which `users`.\n",
    "3. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           errors  total_samples  error_percent\n",
      "dayofweek                                      \n",
      "0               7            136       5.147059\n",
      "1               6            274       2.189781\n",
      "2               2            149       1.342282\n",
      "3               2            396       0.505051\n",
      "4               3            104       2.884615\n",
      "5               3            271       1.107011\n",
      "6               1            356       0.280899\n",
      "\n",
      "Most error-prone weekday: 0 with 5.15% errors\n"
     ]
    }
   ],
   "source": [
    "dayofweek_test = df.loc[X_test.index, 'dayofweek']\n",
    "error_df = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_pred': y_pred,\n",
    "    'is_error': y_pred != y_test,\n",
    "    'dayofweek': dayofweek_test\n",
    "})\n",
    "\n",
    "\n",
    "errors_by_day = error_df.groupby('dayofweek')['is_error'].sum()\n",
    "\n",
    "total_by_day = df['dayofweek'].value_counts().sort_index()\n",
    "\n",
    "day_stats = pd.DataFrame({\n",
    "    'errors': errors_by_day,\n",
    "    'total_samples': total_by_day\n",
    "})\n",
    "\n",
    "day_stats['error_percent'] = (day_stats['errors'] / day_stats['total_samples']) * 100\n",
    "\n",
    "worst_day = day_stats['error_percent'].idxmax()\n",
    "worst_error = day_stats.loc[worst_day, 'error_percent']\n",
    "\n",
    "print(day_stats)\n",
    "print(f\"\\nMost error-prone weekday: {worst_day} with {worst_error:.2f}% errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labname_code_rvw: 1.22% errors (1/82)\n",
      "labname_lab02: 0.00% errors (0/2)\n",
      "labname_lab03: 100.00% errors (1/1)\n",
      "labname_lab03s: 100.00% errors (1/1)\n",
      "labname_lab05s: 2.78% errors (1/36)\n",
      "labname_laba04: 3.37% errors (6/178)\n",
      "labname_laba04s: 0.00% errors (0/104)\n",
      "labname_laba05: 0.45% errors (1/222)\n",
      "labname_laba06: 4.17% errors (2/48)\n",
      "labname_laba06s: 3.28% errors (2/61)\n",
      "labname_project1: 0.95% errors (9/951)\n",
      "Max error percent: 100.00% for labname_lab03\n"
     ]
    }
   ],
   "source": [
    "labname_cols = [col for col in df.columns if col.startswith('labname_')]\n",
    "\n",
    "max_error_percent = 0\n",
    "max_error_percent_col = None\n",
    "\n",
    "for col in labname_cols:\n",
    "    col_values_test = df.loc[X_test.index, col]\n",
    "\n",
    "    error_df = pd.DataFrame({\n",
    "        'y_true': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'is_error': y_pred != y_test,\n",
    "        col: col_values_test\n",
    "    })\n",
    "\n",
    "    errors = error_df[error_df[col] == 1]['is_error'].sum()\n",
    "    total = df[df[col] == 1].shape[0]\n",
    "\n",
    "    error_percent = (errors / total) * 100 if total > 0 else 0\n",
    "\n",
    "    if error_percent > max_error_percent:\n",
    "        max_error_percent = error_percent\n",
    "        max_error_percent_col = col\n",
    "\n",
    "    print(f\"{col}: {error_percent:.2f}% errors ({errors}/{total})\")\n",
    "    \n",
    "print(f\"Max error percent: {max_error_percent:.2f}% for {max_error_percent_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid_user_0: 0.00% errors (0/2)\n",
      "uid_user_1: 0.00% errors (0/46)\n",
      "uid_user_10: 1.41% errors (1/71)\n",
      "uid_user_11: 0.00% errors (0/5)\n",
      "uid_user_12: 0.00% errors (0/49)\n",
      "uid_user_13: 0.00% errors (0/60)\n",
      "uid_user_14: 0.76% errors (1/132)\n",
      "uid_user_15: 0.00% errors (0/17)\n",
      "uid_user_16: 6.25% errors (2/32)\n",
      "uid_user_17: 0.00% errors (0/34)\n",
      "uid_user_18: 2.86% errors (1/35)\n",
      "uid_user_19: 4.40% errors (4/91)\n",
      "uid_user_2: 0.83% errors (1/121)\n",
      "uid_user_20: 0.00% errors (0/86)\n",
      "uid_user_21: 0.00% errors (0/44)\n",
      "uid_user_22: 14.29% errors (1/7)\n",
      "uid_user_23: 0.00% errors (0/4)\n",
      "uid_user_24: 1.79% errors (1/56)\n",
      "uid_user_25: 1.67% errors (2/120)\n",
      "uid_user_26: 0.00% errors (0/90)\n",
      "uid_user_27: 4.35% errors (1/23)\n",
      "uid_user_28: 0.00% errors (0/60)\n",
      "uid_user_29: 1.56% errors (1/64)\n",
      "uid_user_3: 2.82% errors (2/71)\n",
      "uid_user_30: 2.56% errors (1/39)\n",
      "uid_user_31: 2.67% errors (2/75)\n",
      "uid_user_4: 1.06% errors (2/188)\n",
      "uid_user_6: 8.33% errors (1/12)\n",
      "uid_user_7: 0.00% errors (0/5)\n",
      "uid_user_8: 0.00% errors (0/47)\n",
      "Max error percent: 14.29% (uid_user_22)\n"
     ]
    }
   ],
   "source": [
    "user_cols = [col for col in df.columns if col.startswith('uid_user_')]\n",
    "\n",
    "max_percent = 0\n",
    "max_col = None\n",
    "\n",
    "for col in user_cols:\n",
    "    col_values_test = df.loc[X_test.index, col]\n",
    "\n",
    "    error_df = pd.DataFrame({\n",
    "        'y_true': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'is_error': y_pred != y_test,\n",
    "        col: col_values_test\n",
    "    })\n",
    "\n",
    "    errors = error_df[error_df[col] == 1]['is_error'].sum()\n",
    "    total = df[df[col] == 1].shape[0]\n",
    "\n",
    "    error_percent = (errors / total) * 100 if total > 0 else 0\n",
    "\n",
    "    if error_percent > max_percent:\n",
    "        max_percent = error_percent\n",
    "        max_col = col\n",
    "\n",
    "    print(f\"{col}: {error_percent:.2f}% errors ({errors}/{total})\")\n",
    "\n",
    "print(f'Max error percent: {max_percent:.2f}% ({max_col})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function that takes a list of different models and a corresponding list of parameters (dicts) and returns a dict that contains all the 4 metrics for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(models, params):\n",
    "    for model_name in models:\n",
    "        model_class = eval(model_name)\n",
    "\n",
    "        if model_name == 'SVC':\n",
    "            model_result = model_class(**params[model_name], probability=True).fit(X_train, y_train)\n",
    "        else:\n",
    "            model_result = model_class(**params[model_name]).fit(X_train, y_train)\n",
    "            \n",
    "        y_pred = model_result.predict(X_test)\n",
    "        print(f'{model_name} stats:')\n",
    "\n",
    "        roc_auc = roc_auc_score(y_test, model_result.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "\n",
    "        print(f'accuracy is {accuracy_score(y_test, y_pred)}')\n",
    "        print(f'precision is {precision_score(y_test, y_pred, average='weighted')}')\n",
    "        print(f'recall is {recall_score(y_test, y_pred, average='weighted')}')\n",
    "        print(f'roc_auc is {roc_auc}')  \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier stats:\n",
      "accuracy is 0.9289940828402367\n",
      "precision is 0.9320931192329144\n",
      "recall is 0.9289940828402367\n",
      "roc_auc is 0.9905356256858662\n",
      "\n",
      "\n",
      "DecisionTreeClassifier stats:\n",
      "accuracy is 0.9053254437869822\n",
      "precision is 0.9064400481334297\n",
      "recall is 0.9053254437869822\n",
      "roc_auc is 0.9437356717893015\n",
      "\n",
      "\n",
      "SVC stats:\n",
      "accuracy is 0.8875739644970414\n",
      "precision is 0.8926729169690374\n",
      "recall is 0.8875739644970414\n",
      "roc_auc is 0.9819078521045288\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_list = ['RandomForestClassifier', 'DecisionTreeClassifier', 'SVC']\n",
    "models_params = {\n",
    "    'RandomForestClassifier': {'class_weight': None, 'criterion': 'gini', 'max_depth': 28, 'n_estimators': 50},\n",
    "    'DecisionTreeClassifier': {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 23},\n",
    "    'SVC': {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'}\n",
    "}\n",
    "\n",
    "func(models_list, models_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
