{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 03\n",
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the same dataframe as in the previous exercise.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test` and then get `X_train`, `y_train`, `X_valid`, `y_valid` from the previous `X_train`, `y_train`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>uid_user_15</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   numTrials  hour  uid_user_0  uid_user_1  uid_user_10  uid_user_11  \\\n",
       "0          1     5         0.0         0.0          0.0          0.0   \n",
       "1          2     5         0.0         0.0          0.0          0.0   \n",
       "2          3     5         0.0         0.0          0.0          0.0   \n",
       "3          4     5         0.0         0.0          0.0          0.0   \n",
       "4          5     5         0.0         0.0          0.0          0.0   \n",
       "\n",
       "   uid_user_12  uid_user_13  uid_user_14  uid_user_15  ...  labname_lab03  \\\n",
       "0          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "2          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "3          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "4          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "\n",
       "   labname_lab03s  labname_lab05s  labname_laba04  labname_laba04s  \\\n",
       "0             0.0             0.0             0.0              0.0   \n",
       "1             0.0             0.0             0.0              0.0   \n",
       "2             0.0             0.0             0.0              0.0   \n",
       "3             0.0             0.0             0.0              0.0   \n",
       "4             0.0             0.0             0.0              0.0   \n",
       "\n",
       "   labname_laba05  labname_laba06  labname_laba06s  labname_project1  \\\n",
       "0             0.0             0.0              0.0               1.0   \n",
       "1             0.0             0.0              0.0               1.0   \n",
       "2             0.0             0.0              0.0               1.0   \n",
       "3             0.0             0.0              0.0               1.0   \n",
       "4             0.0             0.0              0.0               1.0   \n",
       "\n",
       "   dayofweek  \n",
       "0          4  \n",
       "1          4  \n",
       "2          4  \n",
       "3          4  \n",
       "4          4  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../datasets/day-of-week-not-scaled.csv')\n",
    "df_scaled = pd.read_csv('../../datasets/dayofweek.csv')\n",
    "df['dayofweek'] = df_scaled['dayofweek']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('dayofweek', axis=1)\n",
    "y = df['dayofweek']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=21, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train SVM, decision tree and random forest again with the best parameters that you got from the 01 exercise with `random_state=21` for all of them.\n",
    "2. Evaluate `accuracy`, `precision`, and `recall` for them on the validation set.\n",
    "3. The result of each cell of the section should look like this:\n",
    "\n",
    "```\n",
    "accuracy is 0.87778\n",
    "precision is 0.88162\n",
    "recall is 0.87778\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.8994082840236687\n",
      "precision is 0.9031327775918397\n",
      "recall is 0.8994082840236687\n"
     ]
    }
   ],
   "source": [
    "svc_params = {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'}\n",
    "svc_model = SVC(**svc_params, random_state=21, probability=True)\n",
    "\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "print(f'accuracy is {accuracy_score(y_test, y_pred)}')\n",
    "print(f'precision is {precision_score(y_test, y_pred, average='weighted')}')\n",
    "print(f'recall is {recall_score(y_test, y_pred, average='weighted')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9023668639053254\n",
      "Precision: 0.9050248872120567\n",
      "Recall: 0.9023668639053254\n"
     ]
    }
   ],
   "source": [
    "tree_params = {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 23}\n",
    "tree_model = DecisionTreeClassifier(**tree_params, random_state=21)\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred, average='weighted')}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred, average='weighted')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9378698224852071\n",
      "Precision: 0.941458739514193\n",
      "Recall: 0.9378698224852071\n"
     ]
    }
   ],
   "source": [
    "forest_params = {'class_weight': None, 'criterion': 'gini', 'max_depth': 28, 'n_estimators': 50}\n",
    "forest_model = RandomForestClassifier(**forest_params, random_state=21)\n",
    "\n",
    "forest_model.fit(X_train, y_train)\n",
    "y_pred = forest_model.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred, average='weighted')}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred, average='weighted')}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Voting classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `VotingClassifier` and the three models that you have just trained, calculate the `accuracy`, `precision`, and `recall` on the validation set.\n",
    "2. Play with the other parameteres.\n",
    "3. Calculate the `accuracy`, `precision` and `recall` on the test set for the model with the best weights in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation] Accuracy: 0.8925925925925926\n",
      "Precision: 0.8970935033371042\n",
      "Recall: 0.8925925925925926\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('rf', forest_model), ('dt', tree_model), ('svm', svc_model)], voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_val_pred = voting_clf.predict(X_valid)\n",
    "\n",
    "accuracy = accuracy_score(y_valid, y_val_pred)\n",
    "precision = precision_score(y_valid, y_val_pred, average='weighted')\n",
    "recall = recall_score(y_valid, y_val_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top validation results:\n",
      "     weights  accuracy  precision    recall\n",
      "5  [3, 1, 2]  0.922222   0.925960  0.922222\n",
      "1  [2, 1, 1]  0.922222   0.925397  0.922222\n",
      "2  [2, 1, 1]  0.922222   0.925397  0.922222\n",
      "4  [1, 1, 2]  0.900000   0.904132  0.900000\n",
      "0  [1, 1, 1]  0.892593   0.897094  0.892593\n"
     ]
    }
   ],
   "source": [
    "weights_list = [\n",
    "    [1, 1, 1],\n",
    "    [2, 1, 1],\n",
    "    [2, 1, 1],   \n",
    "    [1, 2, 1],  \n",
    "    [1, 1, 2],   \n",
    "    [3, 1, 2],   \n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for weights in weights_list:\n",
    "    clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', forest_model),\n",
    "            ('dt', tree_model),\n",
    "            ('svc', svc_model)\n",
    "        ],\n",
    "        voting='soft',\n",
    "        weights=weights\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_val_pred = clf.predict(X_valid)\n",
    "\n",
    "    acc = accuracy_score(y_valid, y_val_pred)\n",
    "    prec = precision_score(y_valid, y_val_pred, average='weighted')\n",
    "    rec = recall_score(y_valid, y_val_pred, average='weighted')\n",
    "\n",
    "    results.append({\n",
    "        'weights': weights,\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df_sorted = results_df.sort_values(by=['accuracy', 'precision'], ascending=False)\n",
    "\n",
    "print(\"\\nTop validation results:\")\n",
    "print(results_df_sorted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92308\n",
      "Precision: 0.92444\n",
      "Recall: 0.92308\n"
     ]
    }
   ],
   "source": [
    "best_weights = results_df_sorted.iloc[0]['weights']\n",
    "final_voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', forest_model),\n",
    "        ('dt', tree_model),\n",
    "        ('svc', svc_model)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=best_weights\n",
    ")\n",
    "\n",
    "final_voting_clf.fit(X_train, y_train)\n",
    "y_test_pred = final_voting_clf.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {test_accuracy:.5f}')\n",
    "print(f'Precision: {test_precision:.5f}')\n",
    "print(f'Recall: {test_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bagging classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `BaggingClassifier` and `SVM` with the best parameters create an ensemble, try different values of the `n_estimators`, use `random_state=21`.\n",
    "2. Play with the other parameters.\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_estimators  accuracy  precision    recall\n",
      "3            30  0.870370   0.876313  0.870370\n",
      "4            50  0.870370   0.876313  0.870370\n",
      "2            20  0.862963   0.870199  0.862963\n",
      "1            10  0.848148   0.857371  0.848148\n",
      "0             5  0.818519   0.828006  0.818519\n"
     ]
    }
   ],
   "source": [
    "best_svc_params = {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'}\n",
    "\n",
    "n_estimators_list = [5, 10, 20, 30, 50]\n",
    "results = []\n",
    "\n",
    "for n in n_estimators_list:\n",
    "    model = BaggingClassifier(\n",
    "        estimator=SVC(**best_svc_params, probability=True),\n",
    "        n_estimators=n,\n",
    "        random_state=21\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict(X_valid)\n",
    "\n",
    "    acc = accuracy_score(y_valid, y_val_pred)\n",
    "    prec = precision_score(y_valid, y_val_pred, average='weighted')\n",
    "    rec = recall_score(y_valid, y_val_pred, average='weighted')\n",
    "\n",
    "    results.append({\n",
    "        'n_estimators': n,\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df_sorted = results_df.sort_values(by=['accuracy', 'precision'], ascending=False)\n",
    "print(results_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_estimators  max_samples  max_features  accuracy  precision    recall\n",
      "17            30          1.0           1.0  0.870370   0.876313  0.870370\n",
      "11            20          1.0           1.0  0.862963   0.870199  0.862963\n",
      "5             10          1.0           1.0  0.848148   0.857371  0.848148\n",
      "15            30          0.7           1.0  0.822222   0.833257  0.822222\n",
      "9             20          0.7           1.0  0.822222   0.832476  0.822222\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 1.0]\n",
    "}\n",
    "\n",
    "grid = list(product(param_grid['n_estimators'], param_grid['max_samples'], param_grid['max_features']))\n",
    "extended_results = []\n",
    "\n",
    "for n, ms, mf in grid:\n",
    "    model = BaggingClassifier(\n",
    "        estimator=SVC(**best_svc_params, probability=True),\n",
    "        n_estimators=n,\n",
    "        max_samples=ms,\n",
    "        max_features=mf,\n",
    "        random_state=21\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict(X_valid)\n",
    "\n",
    "    acc = accuracy_score(y_valid, y_val_pred)\n",
    "    prec = precision_score(y_valid, y_val_pred, average='weighted')\n",
    "    rec = recall_score(y_valid, y_val_pred, average='weighted')\n",
    "\n",
    "    extended_results.append({\n",
    "        'n_estimators': n,\n",
    "        'max_samples': ms,\n",
    "        'max_features': mf,\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec\n",
    "    })\n",
    "\n",
    "extended_df = pd.DataFrame(extended_results)\n",
    "extended_df_sorted = extended_df.sort_values(by=['accuracy', 'precision'], ascending=False)\n",
    "print(extended_df_sorted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Accuracy: 0.89941\n",
      "[TEST] Precision: 0.90120\n",
      "[TEST] Recall: 0.89941\n",
      "[BEST PARAMS] n_estimators=30, max_samples=1.0, max_features=1.0\n"
     ]
    }
   ],
   "source": [
    "best_row = extended_df_sorted.iloc[0]\n",
    "\n",
    "best_model = BaggingClassifier(\n",
    "    estimator=SVC(**best_svc_params, probability=True),\n",
    "    n_estimators=int(best_row['n_estimators']),\n",
    "    max_samples=best_row['max_samples'],\n",
    "    max_features=best_row['max_features'],\n",
    "    random_state=21\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_prec = precision_score(y_test, y_test_pred, average='weighted')\n",
    "test_rec = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(f\"\\n[TEST] Accuracy: {test_acc:.5f}\")\n",
    "print(f\"[TEST] Precision: {test_prec:.5f}\")\n",
    "print(f\"[TEST] Recall: {test_rec:.5f}\")\n",
    "print(f\"[BEST PARAMS] n_estimators={int(best_row['n_estimators'])}, max_samples={best_row['max_samples']}, max_features={best_row['max_features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To achieve reproducibility in this case you will have to create an object of cross-validation generator: `StratifiedKFold(n_splits=n, shuffle=True, random_state=21)`, where `n` you will try to optimize (the details are below).\n",
    "2. Using `StackingClassifier` and the three models that you have recently trained, calculate the `accuracy`, `precision` and `recall` on the validation set, try different values of `n_splits` `[2, 3, 4, 5, 6, 7]` in the cross-validation generator and parameter `passthrough` in the classifier itself,\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision). Use `final_estimator=LogisticRegression(solver='liblinear')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_splits  passthrough  accuracy  precision    recall\n",
      "1          2        False  1.000000   1.000000  1.000000\n",
      "3          3        False  1.000000   1.000000  1.000000\n",
      "5          4        False  1.000000   1.000000  1.000000\n",
      "7          5        False  1.000000   1.000000  1.000000\n",
      "9          6        False  1.000000   1.000000  1.000000\n",
      "10         7         True  1.000000   1.000000  1.000000\n",
      "11         7        False  1.000000   1.000000  1.000000\n",
      "4          4         True  0.996296   0.996380  0.996296\n",
      "6          5         True  0.996296   0.996380  0.996296\n",
      "8          6         True  0.996296   0.996380  0.996296\n",
      "2          3         True  0.996296   0.996354  0.996296\n",
      "0          2         True  0.985185   0.985836  0.985185\n"
     ]
    }
   ],
   "source": [
    "final_est = LogisticRegression(solver='liblinear')\n",
    "\n",
    "n_splits_list = [2, 3, 4, 5, 6, 7]\n",
    "passthrough_options = [True, False]\n",
    "\n",
    "results = []\n",
    "\n",
    "for n in n_splits_list:\n",
    "    for passthrough in passthrough_options:\n",
    "        skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=21)\n",
    "\n",
    "        stack_model = StackingClassifier(\n",
    "            estimators=[\n",
    "                ('rf', forest_model),\n",
    "                ('dt', tree_model),\n",
    "                ('svc', svc_model)\n",
    "            ],\n",
    "            final_estimator=final_est,\n",
    "            cv=skf,\n",
    "            passthrough=passthrough,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        stack_model.fit(X_valid, y_valid)\n",
    "        y_val_pred = stack_model.predict(X_valid)\n",
    "\n",
    "        acc = accuracy_score(y_valid, y_val_pred)\n",
    "        prec = precision_score(y_valid, y_val_pred, average='weighted')\n",
    "        rec = recall_score(y_valid, y_val_pred, average='weighted')\n",
    "\n",
    "        results.append({\n",
    "            'n_splits': n,\n",
    "            'passthrough': passthrough,\n",
    "            'accuracy': acc,\n",
    "            'precision': prec,\n",
    "            'recall': rec\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=['accuracy', 'precision'], ascending=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params: n_splits = 2, passthrough = False\n",
      "\n",
      "Test Accuracy: 0.9379\n",
      "Test Precision: 0.9415\n",
      "Test Recall: 0.9379\n"
     ]
    }
   ],
   "source": [
    "best_params = results_df.iloc[0]\n",
    "print(f\"\\nBest params: n_splits = {best_params['n_splits']}, passthrough = {best_params['passthrough']}\")\n",
    "\n",
    "best_skf = StratifiedKFold(n_splits=int(best_params['n_splits']), shuffle=True, random_state=21)\n",
    "best_stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', forest_model),\n",
    "        ('dt', tree_model),\n",
    "        ('svc', svc_model)\n",
    "    ],\n",
    "    final_estimator=final_est,\n",
    "    cv=best_skf,\n",
    "    passthrough=bool(best_params['passthrough']),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_stack.fit(X_train, y_train)\n",
    "y_test_pred = best_stack.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_prec = precision_score(y_test, y_test_pred, average='weighted')\n",
    "test_rec = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Precision: {test_prec:.4f}\")\n",
    "print(f\"Test Recall: {test_rec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision).\n",
    "2. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which labname and for which users.\n",
    "3. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           errors  total_samples  error_percent\n",
      "dayofweek                                      \n",
      "0               3            136       2.205882\n",
      "1               5            274       1.824818\n",
      "2               4            149       2.684564\n",
      "3               4            396       1.010101\n",
      "4               2            104       1.923077\n",
      "5               0            271       0.000000\n",
      "6               3            356       0.842697\n",
      "\n",
      "Most error-prone weekday: 2 with 2.68% errors\n"
     ]
    }
   ],
   "source": [
    "dayofweek_test = df.loc[X_test.index, 'dayofweek']\n",
    "error_df = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_testy_test_pred':y_test_pred,\n",
    "    'is_error':y_test_pred != y_test,\n",
    "    'dayofweek': dayofweek_test\n",
    "})\n",
    "\n",
    "\n",
    "errors_by_day = error_df.groupby('dayofweek')['is_error'].sum()\n",
    "\n",
    "total_by_day = df['dayofweek'].value_counts().sort_index()\n",
    "\n",
    "day_stats = pd.DataFrame({\n",
    "    'errors': errors_by_day,\n",
    "    'total_samples': total_by_day\n",
    "})\n",
    "\n",
    "day_stats['error_percent'] = (day_stats['errors'] / day_stats['total_samples']) * 100\n",
    "\n",
    "worst_day = day_stats['error_percent'].idxmax()\n",
    "worst_error = day_stats.loc[worst_day, 'error_percent']\n",
    "\n",
    "print(day_stats)\n",
    "print(f\"\\nMost error-prone weekday: {worst_day} with {worst_error:.2f}% errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labname_code_rvw: 1.22% errors (1/82)\n",
      "labname_lab02: 0.00% errors (0/2)\n",
      "labname_lab03: 0.00% errors (0/1)\n",
      "labname_lab03s: 0.00% errors (0/1)\n",
      "labname_lab05s: 2.78% errors (1/36)\n",
      "labname_laba04: 2.25% errors (4/178)\n",
      "labname_laba04s: 0.00% errors (0/104)\n",
      "labname_laba05: 0.90% errors (2/222)\n",
      "labname_laba06: 6.25% errors (3/48)\n",
      "labname_laba06s: 1.64% errors (1/61)\n",
      "labname_project1: 0.95% errors (9/951)\n",
      "Max error percent: 6.25% for labname_laba06\n"
     ]
    }
   ],
   "source": [
    "labname_cols = [col for col in df.columns if col.startswith('labname_')]\n",
    "\n",
    "max_error_percent = 0\n",
    "max_error_percent_col = None\n",
    "\n",
    "for col in labname_cols:\n",
    "    col_values_test = df.loc[X_test.index, col]\n",
    "\n",
    "    error_df = pd.DataFrame({\n",
    "        'y_true': y_test,\n",
    "        'y_test_pred': y_test_pred,\n",
    "        'is_error': y_test_pred != y_test,\n",
    "        col: col_values_test\n",
    "    })\n",
    "\n",
    "    errors = error_df[error_df[col] == 1]['is_error'].sum()\n",
    "    total = df[df[col] == 1].shape[0]\n",
    "\n",
    "    error_percent = (errors / total) * 100 if total > 0 else 0\n",
    "\n",
    "    if error_percent > max_error_percent:\n",
    "        max_error_percent = error_percent\n",
    "        max_error_percent_col = col\n",
    "\n",
    "    print(f\"{col}: {error_percent:.2f}% errors ({errors}/{total})\")\n",
    "    \n",
    "print(f\"Max error percent: {max_error_percent:.2f}% for {max_error_percent_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid_user_0: 0.00% errors (0/2)\n",
      "uid_user_1: 0.00% errors (0/46)\n",
      "uid_user_10: 0.00% errors (0/71)\n",
      "uid_user_11: 0.00% errors (0/5)\n",
      "uid_user_12: 0.00% errors (0/49)\n",
      "uid_user_13: 1.67% errors (1/60)\n",
      "uid_user_14: 1.52% errors (2/132)\n",
      "uid_user_15: 0.00% errors (0/17)\n",
      "uid_user_16: 3.12% errors (1/32)\n",
      "uid_user_17: 0.00% errors (0/34)\n",
      "uid_user_18: 0.00% errors (0/35)\n",
      "uid_user_19: 1.10% errors (1/91)\n",
      "uid_user_2: 0.83% errors (1/121)\n",
      "uid_user_20: 0.00% errors (0/86)\n",
      "uid_user_21: 2.27% errors (1/44)\n",
      "uid_user_22: 0.00% errors (0/7)\n",
      "uid_user_23: 0.00% errors (0/4)\n",
      "uid_user_24: 3.57% errors (2/56)\n",
      "uid_user_25: 0.00% errors (0/120)\n",
      "uid_user_26: 1.11% errors (1/90)\n",
      "uid_user_27: 8.70% errors (2/23)\n",
      "uid_user_28: 0.00% errors (0/60)\n",
      "uid_user_29: 1.56% errors (1/64)\n",
      "uid_user_3: 0.00% errors (0/71)\n",
      "uid_user_30: 5.13% errors (2/39)\n",
      "uid_user_31: 1.33% errors (1/75)\n",
      "uid_user_4: 1.60% errors (3/188)\n",
      "uid_user_6: 16.67% errors (2/12)\n",
      "uid_user_7: 0.00% errors (0/5)\n",
      "uid_user_8: 0.00% errors (0/47)\n",
      "Max error percent: 16.67% (uid_user_6)\n"
     ]
    }
   ],
   "source": [
    "user_cols = [col for col in df.columns if col.startswith('uid_user_')]\n",
    "\n",
    "max_percent = 0\n",
    "max_col = None\n",
    "\n",
    "for col in user_cols:\n",
    "    col_values_test = df.loc[X_test.index, col]\n",
    "\n",
    "    error_df = pd.DataFrame({\n",
    "        'y_true': y_test,\n",
    "        'y_test_pred': y_test_pred,\n",
    "        'is_error': y_test_pred != y_test,\n",
    "        col: col_values_test\n",
    "    })\n",
    "\n",
    "    errors = error_df[error_df[col] == 1]['is_error'].sum()\n",
    "    total = df[df[col] == 1].shape[0]\n",
    "\n",
    "    error_percent = (errors / total) * 100 if total > 0 else 0\n",
    "\n",
    "    if error_percent > max_percent:\n",
    "        max_percent = error_percent\n",
    "        max_col = col\n",
    "\n",
    "    print(f\"{col}: {error_percent:.2f}% errors ({errors}/{total})\")\n",
    "\n",
    "print(f'Max error percent: {max_percent:.2f}% ({max_col})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ex03model.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'ex03model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
